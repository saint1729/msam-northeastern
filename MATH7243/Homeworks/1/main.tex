\documentclass[11pt]{amsart}
\usepackage[margin=1in]{geometry}
\usepackage[all]{xy}


\usepackage{amsmath,amsthm,amssymb,color,latexsym}
\usepackage{geometry}        
\geometry{letterpaper}    
\usepackage{graphicx}

\usepackage{listings}
\usepackage{xcolor}

\usepackage[export]{adjustbox}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},   commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2
}

\lstset{style=mystyle}

\usepackage{graphicx}
\graphicspath{ {./images/} }


\newtheorem{problem}{Problem}

\newenvironment{solution}[1][\it{Solution}]{\textbf{#1. } }{$\square$}














\usepackage{txfonts}
\usepackage{amsmath,amsthm,verbatim}
\usepackage{amscd,amssymb}
\usepackage[all]{xy} 
\usepackage{graphicx,calrsfs} 
\usepackage[colorlinks,plainpages,urlcolor=blue]{hyperref} 
\usepackage{breakurl}
\def\UrlBreaks{\do\/\do-}\usepackage{bbm}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{xstring}
\usepackage{tikz}
\usetikzlibrary{matrix,arrows,decorations.pathmorphing,calc,shapes}
\usepackage{mathtools}
\usepackage{tcolorbox}
\usepackage{wrapfig} 

\setlength{\parskip}{0.1 in}
\setlength{\parindent}{0pt}

%\usepackage[utf8]{inputenc}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
   % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

 \lstset{style=mystyle}



\topmargin=0in
\textwidth6.6in
\textheight8.6in
\oddsidemargin=-0.1in
\evensidemargin=-0.1in

\newtheorem{theorem}{Theorem} 
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{question}[theorem]{Question}
\newtheorem{ex}[theorem]{Example}

 
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\kk}{\mathbbm{k}}
\newcommand{\mm}{\mathbbm{m}}

\newcommand{\vtheta}{\vec{\theta}}


\newcommand{\va}{\vec{a}}
\newcommand{\vb}{\vec{b}}
\newcommand{\vc}{\vec{c}}
\newcommand{\vd}{\vec{d}}
\newcommand{\vh}{\vec{h}}
\newcommand{\e}{\vec{e}}
\newcommand{\vu}{\vec{u}}
\newcommand{\vv}{\vec{v}}
\newcommand{\vw}{\vec{w}}
\newcommand{\vx}{\vec{x}}
\newcommand{\vy}{\vec{y}}
\newcommand{\vz}{\vec{z}}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\red}{\textcolor{red}}
\newcommand{\blue}{\textcolor{blue}}
\newcommand{\green}{\textcolor{green}}
\newcommand{\ifif}{\textcolor{blue}{ if and only if }} 


\newcommand{\cB}{\mathcal{B}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}

\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\coker}{coker}
 \DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\Nul}{\mathrm{Nul}}
\DeclareMathOperator{\Co}{\mathrm{Col}}
\DeclareMathOperator{\Ro}{\mathrm{Row}}
\DeclareMathOperator{\Ker}{\mathrm{Ker}}
\DeclareMathOperator{\Ima}{\mathrm{Im}}
\DeclareMathOperator{\dist}{\mathrm{dist}}
\DeclareMathOperator{\proj}{\mathrm{proj}}
\DeclareMathOperator{\refl}{\mathrm{ref}}
\DeclareMathOperator{\sign}{\mathrm{sign}}

\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\tr}{tr}

\newcommand{\ef}{\textbf{ref}}
\newcommand{\rref}{\textbf{rref}}

\newcommand{\pdf}{\textbf{pdf }}
\newcommand{\pmf}{\textbf{pmf }}
\newcommand{\cdf}{\textbf{cdf }}

\newcommand{\normalcdf}{\textbf{normalcdf}}
\newcommand{\invNorm}{\textbf{invNorm}}
\newcommand{\invT}{\textbf{invT}}
\newcommand{\popdf}{\textbf{poissonpdf}}
\newcommand{\pocdf}{\textbf{poissoncdf}}

\DeclareMathOperator{\Var}{\mathrm{Var}}
\DeclareMathOperator{\Cov}{\mathrm{Cov}}
\DeclareMathOperator{\Corr}{\mathrm{Corr}}

\DeclareMathOperator{\Normal}{\mathrm{Normal}}

 \pgfmathdeclarefunction{gauss}{2}{%
  \pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%
}


  
 









\begin{document}
\noindent MATH 7243, Spring 2022\hfill Homework 1.  Matrix calculus\\
Sakshi Suman (01/29/2022)\hfill suman.sak@northeastern.edu

\hrulefill


\begin{problem}
Assume $\vx\in \R^n$,  $A\in \R^{m\times n}$ and $\vb\in \R^m$. Let $f(\vx)=\vb^T A \vx$. Find  $\nabla f$. 
\end{problem}
\begin{solution}
We know that,
\begin{align*}
P(X=x, Y=y, Z=z)=P(Y=y) \cdot P(Z=z \mid Y=y) \cdot P(X=x \mid Z=z, Y=y)
\end{align*}
Therefore,
\begin{align*}
\sum_{z \in \mathcal{Z}} P(X=x \mid Y=y, Z=z) \cdot P(Z=z \mid Y=y) & = \sum_{z \in \mathcal{Z}} \frac{P(X=x, Y=y, Z=z)}{P(Y=y)}\\
													& = \frac{P(X=x, Y=y)}{P(Y=y)} \\
													& = P(X=x \mid Y=y)
\end{align*}

\end{solution} 

\begin{problem}
Let $X$ be a random variable on $\mathcal{X}=\{a, b, c\}$ with the probability mass function $p(x) .$ Let $p(a)=0.1, p(b)=0.2,$ and $p(c)=0.7$ and some function $f(x)$ be
$$
f(x)=\left\{\begin{array}{ll}
10 & x=a \\
5 & x=b \\
\frac{10}{7} & x=c
\end{array}\right.
$$
a) (5 points) What is $\mathbb{E}[f(X)]$ ?\\
b) (5 points) What is $\mathbb{E}[1 / p(X)] ?$\\
c) (5 points) For an arbitrary finite set $\mathcal{X}$ with $n$ elements and arbitrary $p(x)$ on $\mathcal{X}$, what is $\mathbb{E}[1 / p(X)]$ ?
\end{problem}
\begin{solution}
$$
f(x)=\left\{\begin{array}{ll}
10 & x=a \\
5 & x=b \\
\frac{10}{7} & x=c
\end{array}\right.
$$
a)
\begin{align*}
\qquad \mathbb{E}[f(x)] & =\sum_{x \in \mathcal{X}} f(X=x) \times p(X=x) \\
& = 10 \times 0.1+5 \times 0.2+\frac{10}{7} \times 0.7 \\
& = \boxed{3}
\end{align*}
b)
\begin{align*}
\mathbb{E}\left[\frac{1}{p(X)}\right] &=\sum_{x \in \mathcal{X}} \frac{1}{p(X=x)} \times p(X = x) \\
&=1+1+1 \\
&=\boxed{3}
\end{align*}
c)
Let, 
$$
\mathcal{X} = \left\{x_{1}, x_{2}, \ldots, x_{n}\right\}
$$
\begin{align*}
\mathbb{E}\left[\frac{1}{p(x)}\right] &=\sum_{x \in \mathcal{X}} \frac{1}{p(X=x)} \times p(X=x) \\
&=\sum_{i=1}^{n} 1 \\
&=\boxed{n}
\end{align*}
\end{solution}


\begin{problem}
A biased four-sided die is rolled and the down face is a random variable $X$ described by the following $\mathrm{pmf}$
$$
p(x)=\left\{\begin{array}{ll}
x / 10 & x=1,2,3,4 \\
0 & \text { otherwise }
\end{array}\right.
$$
Given the random variable $X$ a biased coin is flipped and the random variable $Y$ is 1 or zero according to whether the coin shows heads or tails. The conditional pmf is
$$
p(y \mid x)=\left(\frac{x+1}{2 x}\right)^{y}\left(1-\frac{x+1}{2 x}\right)^{1-y}
$$
where $y \in\{0,1\}$.\\
a) (5 points) Find the expectation $\mathbb{E}[X]$ and variance $V[X]$.\\
b) (5 points) Find the conditional $\operatorname{pmf} p(x \mid y)$.\\
c) (5 points) Find the conditional expectation $\mathbb{E}[X \mid Y=1] ;$ i.e., the expectation with respect to the conditional $\operatorname{pmf} p_{X \mid Y}(x \mid 1)$.
\end{problem}

\begin{solution}
Given,
$$
p(x)=\left\{\begin{array}{ll}
x / 10 & x=1,2,3,4 \\
0 & \text { otherwise }
\end{array}\right.
$$
$$
p(y \mid x)=\left(\frac{x+1}{2 x}\right)^{y}\left(1-\frac{x+1}{2 x}\right)^{1-y}
$$
where $y \in\{0,1\}$.\\
a)
\begin{align*}
\mathbb{E}[x] &=\sum_{x \in\{1,2,3,4\}} x \cdot p(X=x) \\
&=1 \times \frac{1}{10}+2 \times \frac{2}{10}+3 \times \frac{3}{10}+4 \times \frac{4}{10} \\
&=\frac{30}{10}\\
&=\boxed{3}\\\\
\mathbb{E}\left[X^{2}\right] &=\sum_{x \in \mathcal{X}} x^{2} p(X=x) \\
&=1^{2} \times \frac{1}{10}+2^{2} \times \frac{2}{10}+3^{2} \times \frac{3}{10}+4^{2}\times\frac{4}{10}\\
&=10\\\\
\mathbb{V}\left[X\right] &= \mathbb{E}\left[X^{2}\right] - \left(\mathbb{E}\left[X\right]\right)^{2}\\
&= 10 - 9\\
&= \boxed{1}
\end{align*}
b)
\begin{align*}
p(x \mid y)&=\frac{p(y \mid x) p(x)}{p(y)}\\
&=\frac{p(y \mid x) \times p(x)}{\sum_{x \in \mathcal{X}} p(y \mid x) \times p(x)}\\
&=\frac{\left(\frac{x+1}{2 x}\right)^{y}\left(1-\frac{x+1}{2 x}\right)^{1-y} \times \frac{x}{10}}{\left({\frac{2}{2}}^{y} \times 0^{1-y} \times \frac{1}{10}+\left(\frac{3}{4}\right)^{y}\left(\frac{1}{4}\right)^{1-y}\times\frac{2}{10}+\left(\frac{2}{3}\right)^{y}\left(\frac{1}{3}\right)^{1-y}\times\frac{3}{10}+\left(\frac{5}{8}\right)^{y}\left(\frac{3}{8}\right)^{1-y}\times\frac{4}{10}\right)}\\
&=\frac{2 \times \left(\frac{x+1}{2 x}\right)^{y}\left(1-\frac{x+1}{2 x}\right)^{1-y} \times x}{\left(1^{y} \times 0^{1-y} \times 2+3^{y}\times1^{1-y}\times4+4^{y}\times2^{1-y}\times6+5^{y}\times3^{1-y}\times8\right)}\\
\end{align*}
Writing it in piecewise form,
$$
p(x \mid y)=\left\{\begin{array}{ll}
\frac{x-1}{6} & y=0 \\
\frac{x+1}{14} & y=1
\end{array}\right.
$$

c)
\begin{align*}
\mathbb{E}[X \mid Y=1]=\sum_{x \in \mathcal{X}} x \cdot p_{X \mid Y}(x \mid 1)
\end{align*}

\begin{align*}
p_{X \mid Y}(x \mid 1)&=\frac{\left(\frac{x+1}{2x}\right)^{1} \times\left(1-\frac{x+1}{2 x}\right)^{0} \times \frac{x}{10}}{1^{1} \times 0^{0} \times \frac{1}{10}+\left(\frac{3}{4}\right)^{1} \times\left(\frac{1}{4}\right)^{0} \times \frac{2}{10} + \left(\frac{4}{6}\right)^{1} \times\left(\frac{2}{6}\right)^{0} \times \frac{3}{10} + \left(\frac{5}{8}\right)^{1} \times\left(\frac{3}{8}\right)^{0} \times \frac{4}{10}}\\
&=\frac{x+1}{14}
\end{align*}

\begin{align*}
\mathbb{E}[X \mid Y=1] &= \sum_{x \in \mathcal{X}} x \times \frac{x + 1}{14}\\
&= 1 \times \frac{2}{14} + 2 \times \frac{3}{14} + 3 \times \frac{4}{14} + 4 \times \frac{5}{14}\\
&= \boxed{\frac{20}{7}} 
\end{align*}

\end{solution}



\begin{problem}
Suppose that the data set $\mathcal{D}=\{1,0,1,1,1,0,1,1,1,0\}$ is an i.i.d. sample form a Bernoulli distribution
$$
p(x \mid \alpha)=\alpha^{x}(1-\alpha)^{1-x} \quad 0<\alpha<1
$$
with an unknown parameter $\alpha$.\\
a) (5 points) Calculate the log-likelihood of the data $\mathcal{D}$ when $\alpha=\frac{1}{e} ;$ i.e., find $\log p(\mathcal{D} \mid \alpha=\frac{1}{e})$. The parameter $e$ is the Euler number. Write the final expression as compactly as you can.\\
b) (10 points) Compute the maximum likelihood estimate of $\alpha$. Show all your work.\\
c) (10 points) Suppose the prior distribution for $\alpha$ is the uniform distribution on (0,1).  Compute the Bayes estimator for $\alpha .$ Note that $\int_{0}^{1} v^{m}(1-v)^{r} d v=\frac{m ! r !}{(m+r+1) !}$
\end{problem}

\begin{solution}
a)
\begin{align*}
p(\mathcal{D} \mid \alpha) &= p(\left\{x_i\right\}_{i=1}^{n} \mid \alpha)\\
&= \prod_{i=1}^{n} p(x_i \mid \alpha)\\
&= \alpha^{\sum_{i=1}^{n}x_i} \cdot \left(1-\alpha \right)^{n - \sum_{i=1}^{n}x_i}\\
\end{align*}

\begin{align*}
ll\left(\mathcal{D}, \alpha\right) &= \ln \alpha \cdot \sum_{i=1}^{n}x_i + \ln \left(1-\alpha \right) \cdot \left(n-\sum_{i=1}^{n}x_i\right)\\
ll\left(\mathcal{D}, \frac{1}{e}\right) &= 3\ln\left(e-1\right)-10
\end{align*}

b)
\begin{align*}
\frac{\partial ll\left(\mathcal{D}, \alpha\right)}{\partial \alpha} &= \frac{\sum_{i=1}^{n}x_i}{\alpha} - \frac{n-\sum_{i=1}^{n}x_i}{1-\alpha}\\
&=0
\end{align*}
\begin{align*}
\implies \left(1-\alpha_{ML} \right) \cdot \sum_{i=1}^{n}x_i - \left(n - \sum_{i=1}^{n} x_i \right) \cdot \alpha_{ML} = 0\\
\alpha_{ML} = \frac{\sum_{i=1}^{n}x_i}{n} = \boxed {\frac{7}{10}}
\end{align*}

c)
\begin{align*}
p\left(\mathcal{D}\mid\alpha\right) &= \alpha^{\sum_{i=1}^{n}x_i} \cdot (1-\alpha)^{n-\sum_{i=1}^{n}x_i}\\
p\left(\alpha\right) &= 1\\
p\left(\alpha \mid \mathcal{D}\right) &= \frac{p\left(\mathcal{D} \mid \alpha \right) \cdot p\left(\alpha\right)}{p\left( \mathcal{D} \right)}\\
p\left( \mathcal{D} \right) &= \int_{0}^{1} p\left(\mathcal{D} \mid \alpha \right) p\left(\alpha \right)\,d\alpha\\
&=\int_{0}^{1} \alpha^7 \left(1-\alpha\right)^3 \, d\alpha\\
&=\frac{7!\cdot3!}{11!}
\end{align*}

\begin{align*}
\alpha_{B} &= \int_{0}^{1} \alpha \, p\left(\alpha \mid \mathcal{D}\right) \, d\alpha\\
&= \int_{0}^{1}\frac{\alpha \times \alpha^7 \times \left(1-\alpha\right)^{3} \times 1}{p\left(\mathcal{D}\right)} \, d\alpha\\
&= \frac{\int_{0}^{1}\alpha^8 \times \left(1-\alpha \right)^{3} \, d\alpha}{\frac{7! \cdot 3!}{11!}}\\
&= \boxed{\frac{2}{3}}
\end{align*}
\end{solution}


\begin{problem}
Let $\mathcal{D}=\left\{x_{i}\right\}_{i=1}^{n}$ be an i.i.d. sample from
$$
p(x)=\left\{\begin{array}{ll}
e^{-\left(x-\theta_{0}\right)} & x \geq \theta_{0} \\
0 & \text { otherwise }
\end{array}\right.
$$
Determine $\theta_{\mathrm{ML}}$ - the maximum likelihood estimate of $\theta_{0}$.
\end{problem}
\begin{solution}

\begin{align*}
p(x)&=\left\{\begin{array}{ll}
e^{-\left(x-\theta_{0}\right)} & x \geq \theta_{0} \\
0 & \text { otherwise }
\end{array}\right.\\
\mathcal{D}&=\left\{x_{i}\right\}_{i=1}^{n}
\end{align*}

For $\theta_0 \le min\left(\left\{x_i\right\}_{i=1}^{n}\right)$, 
\begin{align*}
p\left(\mathcal{D} \mid \theta_0 \right) &= p\left(\left\{x_{i}\right\}_{i=1}^{n} \mid \theta_0\right)\\
&= \prod_{i=1}^{n}p\left(x_i \mid \theta_0\right)\\
&= e^{-\left(\sum_{i=1}^{n}x_i-n \cdot \theta_0\right)}
\end{align*}

For $\theta_0 > min\left(\left\{x_i\right\}_{i=1}^{n}\right)$, 
\begin{align*}
p\left(\mathcal{D} \mid \theta_0 \right) &= 0
\end{align*}

This is a strictly increasing function w.r.t.  $\theta_0$ until $\theta_0 = min\left(\left\{x_i\right\}_{i=1}^{n}\right)$ and then falls to $0$ after that.\\

Thefore, the maximum likelihood

$$\theta_{ML} = min\left(\left\{x_i\right\}_{i=1}^{n}\right)$$

\end{solution}



\end{document}
